import logging
import os
import uuid
import time
from dotenv import load_dotenv
import joblib
from aiogram import Bot, Dispatcher, executor, types
from aiogram.types import ParseMode, InlineKeyboardMarkup, InlineKeyboardButton, ReplyKeyboardMarkup, KeyboardButton
from aiogram.utils.callback_data import CallbackData
from aiogram.dispatcher import FSMContext
from aiogram.dispatcher.filters.state import State, StatesGroup
from aiogram.contrib.fsm_storage.memory import MemoryStorage # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è

from clickhouse_driver import Client

import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer


load_dotenv()
logging.basicConfig(
    format="%(levelname)s: %(asctime)s - %(message)s",
    datefmt="%d-%b-%y %H:%M:%S",
    level=logging.INFO,
)

APP_TOKEN = os.getenv("APP_TOKEN")
if not APP_TOKEN:
    logging.critical("–¢–æ–∫–µ–Ω –±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    raise ValueError("–¢–æ–∫–µ–Ω –±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω!")


storage = MemoryStorage()
bot = Bot(token=APP_TOKEN)
dp = Dispatcher(bot, storage=storage)

class NewsAnalysis(StatesGroup):
    waiting_for_model_choice = State()
    waiting_for_news_text = State()

CH_HOST = os.getenv("CH_HOST", "clickhouse-server")
CH_PORT = int(os.getenv("CH_PORT", 9000))
CH_USER = os.getenv("CH_USER", "bot_user")
CH_PASSWORD = os.getenv("CH_PASSWORD", "")
CH_DB = os.getenv("CH_DB", "fakenews_db")
db_client = None

def get_clickhouse_client():
    global db_client
    reconnect_needed = False

    if db_client is None:
        reconnect_needed = True
    else:
        try:
            db_client.execute("SELECT 1")
        except Exception as e:
            logging.warning(f"–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å ClickHouse –ø–æ—Ç–µ—Ä—è–Ω–æ –∏–ª–∏ –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ: {e}. –ü–æ–ø—ã—Ç–∫–∞ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è.")
            reconnect_needed = True
            if db_client and db_client.connection:
                try:
                    db_client.disconnect()
                except Exception:
                    pass
            db_client = None

    if reconnect_needed:
        try:
            logging.info(f"–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ ClickHouse ({CH_HOST}:{CH_PORT}, –ë–î: {CH_DB})...")
            db_client = Client(
                host=CH_HOST, port=CH_PORT, user=CH_USER, password=CH_PASSWORD, database=CH_DB,
                connect_timeout=10, send_receive_timeout=300,
                settings={'max_block_size': 100000}
            )
            db_client.execute("SELECT 1")
            logging.info(f"–£—Å–ø–µ—à–Ω–æ–µ –Ω–æ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ClickHouse ({CH_HOST}:{CH_PORT}, –ë–î: {CH_DB})")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –Ω–æ–≤–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ ClickHouse: {e}")
            db_client = None

    return db_client


get_clickhouse_client()


MODEL_DIR = "models"
VECTORIZER_PATH = os.path.join(MODEL_DIR, "vectorizer_new.pkl")
MODELS_CONFIG = {
    "model_1": {
        "path": os.path.join(MODEL_DIR, "lsvc_model_new.pkl"),
        "name": "LinearSVC (–ë—ã—Å—Ç—Ä–∞—è)",
        "description": "–õ–∏–Ω–µ–π–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä. –ë—ã—Å—Ç—Ä—ã–π, —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–∞."
    },
    "model_2": {
        "path": os.path.join(MODEL_DIR, "lgbm_model_new.pkl"),
        "name": "LightGBM (–¢–æ—á–Ω–∞—è)",
        "description": "–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥. –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω–µ–µ."
    }
}
models_loaded = {}
vectorizer = None

try:
    if not os.path.exists(VECTORIZER_PATH):
        raise FileNotFoundError(f"–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω: {VECTORIZER_PATH}")
    vectorizer = joblib.load(VECTORIZER_PATH)
    logging.info("–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")

    for model_id, config in MODELS_CONFIG.items():
        if not os.path.exists(config["path"]):
            raise FileNotFoundError(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ '{model_id}' –Ω–µ –Ω–∞–π–¥–µ–Ω: {config['path']}")
        models_loaded[model_id] = joblib.load(config["path"])
        logging.info(f"–ú–æ–¥–µ–ª—å '{config['name']}' ({model_id}) —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

except Exception as e:
    logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
    raise


try:
    lemmatizer = WordNetLemmatizer()
    stop_words = set(stopwords.words('english'))
    logging.info("NLTK —Ä–µ—Å—É—Ä—Å—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.")
except LookupError as e:
    logging.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ NLTK —Ä–µ—Å—É—Ä—Å–æ–≤: {e}. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–∫–µ—Ç—ã —Å–∫–∞—á–∞–Ω—ã.")
    raise

def preprocess_text(text: str) -> str:
    if not isinstance(text, str):
        logging.warning(f"preprocess_text –ø–æ–ª—É—á–∏–ª –Ω–µ —Å—Ç—Ä–æ–∫—É: {type(text)}. –í–æ–∑–≤—Ä–∞—â–∞—é –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.")
        return ""
    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))
    tokens = word_tokenize(text)
    processed_tokens = []
    for word in tokens:
        if word not in stop_words and word.isalpha():
            processed_tokens.append(lemmatizer.lemmatize(word))
    return " ".join(processed_tokens)



async def predict_fake_news(news_text: str, model_id: str) -> tuple[str, float | None]:
    if model_id not in models_loaded:
        logging.error(f"–ó–∞–ø—Ä–æ—à–µ–Ω–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {model_id}")
        return "–û—à–∏–±–∫–∞: –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", None
    
    selected_model = models_loaded[model_id]
    model_friendly_name = MODELS_CONFIG[model_id]["name"]

    try:
        preprocessed_text = preprocess_text(news_text)
        if not preprocessed_text.strip():
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç", None

        text_vector = vectorizer.transform([preprocessed_text])
        prediction = selected_model.predict(text_vector)[0]
        
        probability = None
        if hasattr(selected_model, "predict_proba"):
            proba = selected_model.predict_proba(text_vector)[0]
            probability = float(max(proba))

        label = "FAKE ü§•" if prediction == 1 else "REAL ‚úÖ"
        logging.info(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é '{model_friendly_name}': {label}, {probability}")
        return label, probability
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ —Å –º–æ–¥–µ–ª—å—é {model_friendly_name}: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ({model_friendly_name})", None



async def log_request_to_db(user_id: int, chat_id: int, message_id: int,
                            news_text: str, predicted_label: str,
                            probability: float | None, processing_time_ms: int,
                            selected_model_id: str) -> str | None:
    client = get_clickhouse_client()
    if not client:
        logging.warning("–ù–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è.")
        return None

    request_id_uuid = uuid.uuid4()
    request_id = str(request_id_uuid)
    model_version_to_log = MODELS_CONFIG.get(selected_model_id, {}).get("name", selected_model_id)

    data_to_insert = [{
        "request_id": request_id_uuid,
        "user_id": user_id,
        "chat_id": chat_id,
        "message_id": message_id,
        "news_text": news_text,
        "predicted_label": predicted_label,
        "prediction_probability": probability if probability is not None else 0.0,
        "model_version": model_version_to_log,
        "processing_time_ms": processing_time_ms
    }]

    columns = "(request_id, user_id, chat_id, message_id, news_text, predicted_label, prediction_probability, model_version, processing_time_ms)"

    try:
        client.execute(f"INSERT INTO {CH_DB}.requests_log {columns} VALUES", data_to_insert)
        logging.info(f"–ó–∞–ø—Ä–æ—Å {request_id} (–º–æ–¥–µ–ª—å: {model_version_to_log}) –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω –≤ –ë–î.")
        return request_id
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ {request_id} –≤ –ë–î: {e}", exc_info=True)
        return None


async def log_feedback_to_db(request_id: str, user_id: int, user_rating: str): # request_id –ø—Ä–∏—Ö–æ–¥–∏—Ç –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞
    client = get_clickhouse_client()
    if not client:
        logging.warning("–ù–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–¥–±–µ–∫–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è.")
        return False

    try:
        request_id_uuid = uuid.UUID(request_id)
    except ValueError:
        logging.error(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç request_id –¥–ª—è UUID: {request_id}")
        return False

    data_to_insert = [{
        "request_id": request_id_uuid,
        "user_id": user_id,
        "user_rating": user_rating
    }]

    columns = "(request_id, user_id, user_rating)"

    try:
        client.execute(f"INSERT INTO {CH_DB}.feedback {columns} VALUES", data_to_insert)
        logging.info(f"–§–∏–¥–±–µ–∫ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ {request_id} (–æ—Ü–µ–Ω–∫–∞: {user_rating}) –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω.")
        return True
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∏–¥–±–µ–∫–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ {request_id} –≤ –ë–î: {e}", exc_info=True)
        return False

feedback_cb = CallbackData("feedback", "request_id", "rating")

def get_feedback_keyboard(request_id: str) -> InlineKeyboardMarkup:
    keyboard = InlineKeyboardMarkup(row_width=2)
    keyboard.add(
        InlineKeyboardButton("üëç –ü—Ä–∞–≤–∏–ª—å–Ω–æ", callback_data=feedback_cb.new(request_id=request_id, rating="correct")),
        InlineKeyboardButton("üëé –û—à–∏–±–∫–∞", callback_data=feedback_cb.new(request_id=request_id, rating="incorrect"))
    )
    return keyboard


def get_model_choice_keyboard() -> ReplyKeyboardMarkup:
    keyboard = ReplyKeyboardMarkup(resize_keyboard=True, one_time_keyboard=True)
    for model_id, config in MODELS_CONFIG.items():
        keyboard.add(KeyboardButton(config["name"]))
    keyboard.add(KeyboardButton("–û—Ç–º–µ–Ω–∞"))
    return keyboard

async def set_default_commands(dp: Dispatcher):
    await dp.bot.set_my_commands([
        types.BotCommand("start", "üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞ / –ü–æ–º–æ—â—å"),
        types.BotCommand("analyze", "üîé –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç—å"),
        types.BotCommand("cancel", "‚ùå –û—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ"),
    ])

@dp.message_handler(commands=["start", "help"], state="*")
async def send_welcome(message: types.Message, state: FSMContext):
    await state.finish()
    user_name = message.from_user.first_name
    await message.reply(
        f"–ü—Ä–∏–≤–µ—Ç, {user_name}! üëã –Ø –±–æ—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–µ–π–∫–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π.\n\n"
        "–í–æ—Ç —á—Ç–æ —è —É–º–µ—é:\n"
        "üëâ /analyze - –ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏ (—è –ø—Ä–µ–¥–ª–æ–∂—É –≤—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å).\n"
        "üëâ /help - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –µ—â–µ —Ä–∞–∑.\n"
        "üëâ /cancel - –û—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏–ª–∏ –≤–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞).\n\n"
        "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ –∫–æ–º–∞–Ω–¥—É, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å!",
        parse_mode=ParseMode.MARKDOWN
    )

@dp.message_handler(state='*', commands='cancel')
@dp.message_handler(lambda message: message.text.lower() == '–æ—Ç–º–µ–Ω–∞', state='*')
async def cancel_handler(message: types.Message, state: FSMContext):
    current_state = await state.get_state()
    if current_state is None:
        await message.reply('–ù–µ—á–µ–≥–æ –æ—Ç–º–µ–Ω—è—Ç—å.', reply_markup=types.ReplyKeyboardRemove())
        return

    logging.info(f'Cancelling state {current_state} for user {message.from_user.id}')
    await state.finish()
    await message.reply('–î–µ–π—Å—Ç–≤–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.', reply_markup=types.ReplyKeyboardRemove())

@dp.message_handler(commands=["analyze"], state="*")
async def cmd_analyze(message: types.Message, state: FSMContext):
    await state.finish()
    await NewsAnalysis.waiting_for_model_choice.set()
    await message.reply("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:", reply_markup=get_model_choice_keyboard())

@dp.message_handler(state=NewsAnalysis.waiting_for_model_choice)
async def process_model_choice(message: types.Message, state: FSMContext):
    chosen_model_name = message.text
    selected_model_id = None
    for model_id, config in MODELS_CONFIG.items():
        if config["name"] == chosen_model_name:
            selected_model_id = model_id
            break
    
    if not selected_model_id:
        await message.reply("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∞ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–µ.",
                            reply_markup=get_model_choice_keyboard())
        return

    await state.update_data(selected_model_id=selected_model_id)
    await NewsAnalysis.waiting_for_news_text.set()
    await message.reply(f"–í—ã–±—Ä–∞–Ω–∞: *{chosen_model_name}*.\n"
                        f"{MODELS_CONFIG[selected_model_id]['description']}\n\n"
                        "–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.",
                        reply_markup=types.ReplyKeyboardRemove(), parse_mode=ParseMode.MARKDOWN)

@dp.message_handler(state=NewsAnalysis.waiting_for_news_text, content_types=types.ContentType.TEXT)
async def process_news_text(message: types.Message, state: FSMContext):
    user_data = await state.get_data()
    selected_model_id = user_data.get("selected_model_id")
    news_text = message.text

    if not selected_model_id:
        logging.error(f"–í —Å–æ—Å—Ç–æ—è–Ω–∏–∏ waiting_for_news_text –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç selected_model_id –¥–ª—è user {message.from_user.id}")
        await message.reply("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞, –º–æ–¥–µ–ª—å –Ω–µ –±—ã–ª–∞ –≤—ã–±—Ä–∞–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ —Å /analyze.")
        await state.finish()
        return

    start_time = time.time()
    logging.info(f"User {message.from_user.id} (–º–æ–¥–µ–ª—å: {selected_model_id}) sent text: '{news_text[:100]}...'")

    status_message = await message.reply("üîé –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –Ω–æ–≤–æ—Å—Ç—å...")

    label, probability = await predict_fake_news(news_text, selected_model_id)
    processing_time_ms = int((time.time() - start_time) * 1000)

    request_id = await log_request_to_db(
        user_id=message.from_user.id, chat_id=message.chat.id, message_id=message.message_id,
        news_text=news_text, predicted_label=label, probability=probability,
        processing_time_ms=processing_time_ms, selected_model_id=selected_model_id
    )

    response_text = f"–†–µ–∑—É–ª—å—Ç–∞—Ç ({MODELS_CONFIG[selected_model_id]['name']}): *{label}*"
    if probability is not None:
        response_text += f"\n–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: *{probability*100:.2f}%*"
    
    reply_markup = get_feedback_keyboard(request_id) if request_id else None
    
    try:
        await status_message.edit_text(response_text, parse_mode=ParseMode.MARKDOWN, reply_markup=reply_markup)
    except Exception:
        await message.reply(response_text, parse_mode=ParseMode.MARKDOWN, reply_markup=reply_markup)


    await state.finish()


@dp.message_handler(state='*', commands='cancel')
@dp.message_handler(lambda message: message.text.lower() == '–æ—Ç–º–µ–Ω–∞', state='*')
async def cancel_handler(message: types.Message, state: FSMContext):
    current_state = await state.get_state()
    if current_state is None:
        await message.reply('–ù–µ—á–µ–≥–æ –æ—Ç–º–µ–Ω—è—Ç—å.', reply_markup=types.ReplyKeyboardRemove())
        return

    logging.info(f'Cancelling state {current_state} for user {message.from_user.id}')
    await state.finish()
    await message.reply('–î–µ–π—Å—Ç–≤–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.', reply_markup=types.ReplyKeyboardRemove())



@dp.callback_query_handler(feedback_cb.filter(), state="*")
async def process_feedback_callback(callback_query: types.CallbackQuery, callback_data: dict, state: FSMContext):
    request_id = callback_data.get("request_id")
    rating = callback_data.get("rating")
    user_id = callback_query.from_user.id

    logging.info(f"–ü–æ–ª—É—á–µ–Ω —Ñ–∏–¥–±–µ–∫ –æ—Ç user {user_id} –¥–ª—è request_id {request_id}: {rating}")
    success = await log_feedback_to_db(request_id, user_id, rating)

    if success:
        await callback_query.answer("–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à –æ—Ç–∑—ã–≤! üòä")

        rating_text = "–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π" if rating == "correct" else "–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π"
        try:
            await bot.send_message(
                chat_id=callback_query.message.chat.id,
                text=f"–í–∞—à {rating_text} –æ—Ç–∑—ã–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É —É—á—Ç–µ–Ω. –°–ø–∞—Å–∏–±–æ!"
            )
        except Exception as e:
            logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ñ–∏–¥–±–µ–∫–∞: {e}", exc_info=True)
        
        try:
            await bot.edit_message_reply_markup(
                chat_id=callback_query.message.chat.id,
                message_id=callback_query.message.message_id,
                reply_markup=None
            )
        except Exception as e:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–±—Ä–∞—Ç—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ—Å–ª–µ —Ñ–∏–¥–±–µ–∫–∞: {e}")

    else:
        await callback_query.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ç–∑—ã–≤–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", show_alert=True)


if __name__ == "__main__":
    logging.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    executor.start_polling(dp, skip_updates=True, on_startup=set_default_commands)
